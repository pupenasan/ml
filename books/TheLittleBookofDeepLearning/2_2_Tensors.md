|                                                              |                    |                                          |
| ------------------------------------------------------------ | ------------------ | ---------------------------------------- |
| [<---   2_1_GPUs_TPUs_and_batches.md](2_1_GPUs_TPUs_and_batches.md) | [Зміст](README.md) | [3__Training.md    --->](3__Training.md) |

## 2.2    Тензори

Графічні процесори та **фреймворки глибокого навчання (deep learning frameworks)**, такі як Py-Torch або JAX, маніпулюють величинами, що підлягають обробці, організовуючи їх у вигляді **тензорів (tensors)**.  Тензор є послідовністю скалярів (scalars), що розташовані уздовж кількох дискретних осей. Це елементи $R^{N_1×···×N_D}$, які узагальнюють поняття векторів та матриць.

Тензори використовуються для представлення сигналів що обробляються, **налаштовуваних параметрів (trainable parameters)** моделей а також проміжних обчислювальних величин. Ці роміжні величини називаються **активаціями (activations)** аналогічно до активації нейронів в нейронних мережах.

Наприклад, часовий ряд (time series) природним чином кодується як тензор $T×D$ або, з історичних причин, як тензор $D×T$, де $T$ — це тривалість часового ряду, а $D$ — розмірність ознак (feature) представлених на кожному кроці часу. Розмірність ознак часто називають кількістю **каналів (channels)**. Подібним чином 2D-структурований сигнал можна представити як тензор $D×H×W$, де $H$ і $W$ є його шириною та висотою. Зображення RGB у даному випадку відповідало б ромірності $D=3$.  Кількість каналів (тобто ромзірність ознак) може бути до кількох тисяч у великих моделях.

Додавання додаткових розмірів дозволяє відображати серію (series) об’єктів. П’ятдесят зображень RGB із роздільною здатністю $32×24$ можна, наприклад, закодувати як тензор $50×3×24×32$

Усі бібліотеки глибокого навчання надають велику кількість операцій, які охоплюють стандартну лінійну алгебру, комплексну зміну форми та вилучення (extraction), а також спеціальні операції глибокого навчання, деякі з яких ми побачимо в [главі 4](4__Model_components.md). Реалізація тензорів відокремлює представлення форми від схеми зберігання коефіцієнтів у пам’яті, що дозволяє виконувати багато операцій зміни форми, транспонування та вилучення без копіювання коефіцієнтів, отже, надзвичайно швидко.

На практиці практично будь-яке обчислення можна розкласти на елементарні тензорні операції, що дозволяє уникнути непаралельних циклів на рівні мови та поганого керування пам’яттю.

Окрім того, що тензори є зручними інструментами, вони допомагають досягти ефективності обчислень. Усі люди, які беруть участь у розробці операційної глибокої моделі, від дизайнерів драйверів, бібліотек і моделей до комп’ютерів і чіпів, знають, що даними будуть маніпулювати як тензорами. Результуючі обмеження на локальність і блочну розкладність дозволяють усім учасникам цього ланцюга придумати оптимальні проекти.

### Від перекладача

- <https://uk.wikipedia.org/wiki/Тензор>
- <https://en.wikipedia.org/wiki/Tensor>
- <https://uk.m.wikipedia.org/wiki/Ознака_(машинне_навчання)>