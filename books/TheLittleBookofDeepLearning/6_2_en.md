## 6.2    Image classification

**Image classification** is the simplest strategy for extracting semantics from an image and consists of predicting a class from a finite, predefined number of classes, given an input image.

The standard models for this task are convolutional networks, such as ResNets (see [ยง 5.2](5_2_Convolutional_networks.md)), and attention-based models such as ViT (see [ยง 5.3](5_3_Attention_models.md)). Those models generate a vector of logits with as many dimensions as there are classes.

The training procedure simply minimizes the cross-entropy loss (see [ยง 3.1](3_1_Losses.md)). Usually, performance can be improved with **data augmentation**, which consists of modifying the training samples with hand-designed random transformations that do not change the semantic content of the image, such as cropping, scaling, mirroring, or color changes.
