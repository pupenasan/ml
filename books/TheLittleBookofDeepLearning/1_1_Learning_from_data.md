[<---   1. Машинне навчання](1__Machine_Learning.md)         [Зміст](README.md)          [1.2 Регресія на основі базисних функцій    --->](1_2_Basis_function_regression.md) 

## 1.1 Навчання на основі даних

Найпростіший випадок використання моделі, навченої на основі даних, — це коли доступний сигнал $x$, наприклад, зображення номерного знака, за яким потрібно передбачити величину $y$, таку як рядок символів, написаних на цьому знаці.

У багатьох реальних ситуаціях, коли $x$ є сигналом великої розмірності, зафіксованим у неконтрольованому середовищі, надто складно придумати аналітичний рецепт, який пов’язує $x$ і $y$.

Що можна зробити, так це зібрати великий **навчальний набір даних (training set)** $\mathscr{D}$ з пар значень ($x_n$,$y_n$) і розробити параметричну модель $f$ та відповідний їй фрагмент комп’ютерного коду, які модулюють його поведінку, що у свою чергу містять **налаштовуванні параметри (trainable parameters)** $w$. Далі шукати значення параметрів $w^*$ такими, щоб ця модель (код) давала хороший прогноз. «Хороший» в даному контексті означає наступне: якщо на цей фрагменту коду дати вхідні дані $x$, то обчислене значення $\hat{y}=f(x;w^*)$ даватиме хорошу оцінку значення $y$, яке пов’язане із $x$ у навчальному наборі, якщо він там був.

Це поняття "хорошого" зазвичай формалізується за допомогою **втрати (loss)** $\mathscr{L}(w)$. Чим менше втрати, тим краще параметрична модель $f(\cdot;w)$ для набору $\mathscr{D}$. Тому **навчання (training)** моделі полягає в обчисленні такого значення параметрів $w^∗$, яке мінімізує функцію втрат $\mathscr{L}(w*)$.

Більшість змісту цієї книги присвячено означенню моделі $f$, яка у реалістичних сценаріях є складною комбінацією попередньо означених під-модулів.

Параметри $w$, що підбирають в процесі навчання, часто називають **вагами (weights)** за аналогією із синаптичними вагами біологічних нейронних мереж. Окрім цих параметрів, моделі зазвичай залежать від **метапараметрів (meta-parameters)**, які встановлюються відповідно до попередніх знань предметної області, найкращих практик або обмежень ресурсів. Вони також можуть бути певним чином оптимізовані, але за допомогою техніки, відмінної від тих, що використовуються для оптимізації параметрів $w$.

### Від перекладача

- [Тренувальний, затверджувальний та випробувальний набори Wiki](https://uk.wikipedia.org/wiki/%D0%A2%D1%80%D0%B5%D0%BD%D1%83%D0%B2%D0%B0%D0%BB%D1%8C%D0%BD%D0%B8%D0%B9,_%D0%B7%D0%B0%D1%82%D0%B2%D0%B5%D1%80%D0%B4%D0%B6%D1%83%D0%B2%D0%B0%D0%BB%D1%8C%D0%BD%D0%B8%D0%B9_%D1%82%D0%B0_%D0%B2%D0%B8%D0%BF%D1%80%D0%BE%D0%B1%D1%83%D0%B2%D0%B0%D0%BB%D1%8C%D0%BD%D0%B8%D0%B9_%D0%BD%D0%B0%D0%B1%D0%BE%D1%80%D0%B8#%D0%A2%D1%80%D0%B5%D0%BD%D1%83%D0%B2%D0%B0%D0%BB%D1%8C%D0%BD%D0%B8%D0%B9_%D0%BD%D0%B0%D0%B1%D1%96%D1%80_%D0%B4%D0%B0%D0%BD%D0%B8%D1%85)